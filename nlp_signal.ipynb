{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 NLP를 통한 알파 리서치\n",
    "\n",
    "네이버 뉴스에서 종목명을 검색해 나오는 뉴스 기사들을 크롤링해 json으로 데이터셋화 시켜놨음. \n",
    "\n",
    "FnGuide의 KF-DeBERTa를 활용해 sentiment score 모델을 만들고 이 score을 통한 D-1 알파(하루 전 시그널로 다음 날 트레이딩) 전략을 만들어 백테스팅. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "from pprint import pprint as pp\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "data_dir = cwd / \"data\"\n",
    "fnguide_dir = data_dir / \"fnguide\"\n",
    "kqdl_dir = data_dir / \"kqdl\"\n",
    "navernews_dir = data_dir / \"navernews\" / \"navernews\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. univ 2000 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_2d = pd.read_pickle(fnguide_dir / \"return_2d.pkl\")\n",
    "tradingmoneyvolume_2d = pd.read_pickle(fnguide_dir / \"tradingmoneyvolume_2d.pkl\")\n",
    "mktcap_2d = pd.read_pickle(fnguide_dir / \"mktcap_2d.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_list = return_2d.columns\n",
    "date_list = return_2d.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 뉴스 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stock_news(sid):\n",
    "    news_path = navernews_dir / sid\n",
    "    file_paths = [p for p in news_path.glob('**/*.json') if p.is_file()]\n",
    "    \n",
    "    news = []\n",
    "    for file_path in file_paths:\n",
    "        jsons = load_json(file_path)['data']\n",
    "        news.extend(jsons)\n",
    "    \n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_news(sid_list):\n",
    "    all_news = []\n",
    "    for sid in sid_list:\n",
    "        all_news.extend(load_stock_news(sid))\n",
    "    \n",
    "    return all_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news = load_all_news(sid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news_df = pd.DataFrame(all_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free up memory\n",
    "\n",
    "del all_news\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['market', 'sid', 'codename', 'year', 'month', 'article_url',\n",
       "       'news_company', 'title', 'headline', 'date_str', 'writer', 'section',\n",
       "       'original_article_link', 'article_body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_news_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market</th>\n",
       "      <th>sid</th>\n",
       "      <th>codename</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>article_url</th>\n",
       "      <th>news_company</th>\n",
       "      <th>title</th>\n",
       "      <th>headline</th>\n",
       "      <th>date_str</th>\n",
       "      <th>writer</th>\n",
       "      <th>section</th>\n",
       "      <th>original_article_link</th>\n",
       "      <th>article_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kospi</td>\n",
       "      <td>000050</td>\n",
       "      <td>경방</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>https://n.news.naver.com/sports/general/articl...</td>\n",
       "      <td>스포츠월드</td>\n",
       "      <td>1월3일 금요 광명경륜, 나윤석 삼복승 왕 가이드</td>\n",
       "      <td>1월3일 금요 광명경륜, 나윤석 삼복승 왕 가이드</td>\n",
       "      <td>2014.01.02. 오전 10:54</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\t\\t\\t▲우수급 11경주 젖히기 능력 우수한 6번 김승현과 이를 활용할 1번...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  market     sid codename  year  month  \\\n",
       "0  kospi  000050       경방  2014      1   \n",
       "\n",
       "                                         article_url news_company  \\\n",
       "0  https://n.news.naver.com/sports/general/articl...        스포츠월드   \n",
       "\n",
       "                         title                     headline  \\\n",
       "0  1월3일 금요 광명경륜, 나윤석 삼복승 왕 가이드  1월3일 금요 광명경륜, 나윤석 삼복승 왕 가이드   \n",
       "\n",
       "               date_str writer section original_article_link  \\\n",
       "0  2014.01.02. 오전 10:54   None    None                  None   \n",
       "\n",
       "                                        article_body  \n",
       "0  \\n\\t\\t\\t▲우수급 11경주 젖히기 능력 우수한 6번 김승현과 이를 활용할 1번...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_news_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 뉴스 데이터셋 전처리\n",
    "\n",
    "- 기사는 발행시간이 적혀있어 Point-in-Time 하므로 신뢰할 수 있는 데이터셋을 구축하는데 용이함. \n",
    "- 00시 자정을 기준으로 날짜를 나누는 것이 아닌, 장마감 시간을 바탕으로 date split\n",
    "    - 장마감~익일 장시작전:\n",
    "        - 익일 이용 가능한 데이터\n",
    "    - 장시작~장마감\n",
    "        - 당일 이용가능하나 look-ahead bias 있을 수 있음. \n",
    "- 본 분석에서는 아래에 나올 긍/부정 레이블링을 제대로 하기 위해 장마감~익일 장시작전 뉴스만 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 뉴스 데이터셋 전처리 (심화)\n",
    "\n",
    "네이버 뉴스에서 단순 종목명 기준으로 검색했기 때문에 대상 기업과 관련 없는 기업들의 기사가 섞여있을 가능성 농후함. \n",
    "\n",
    "예시:\n",
    "- 셀트리온(068270): 이름이 고유하여 관련 없는 기사가 섞일 가능성 적음. \n",
    "- 대상(001680): 이름이 다른 문맥에서 발견되기 쉬움. 연예계 대상, 개인사업자 대상 대출, 등등\n",
    "\n",
    "따라서 이 경우 NER(Named Entity Recognition) Task를 통해 기업/단체명에 해당되는 단어가 검출되는 기사만 남길 필요가 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 커버리지 확인\n",
    "\n",
    "뉴스 데이터셋은 주가 데이터와 달리 모든 종목을 커버하지 못하며, 커버리지 내의 종목들 중에서도 잘 알려진 우량종목에 기사가 편중되어있을 가능성이 높음. \n",
    "\n",
    "즉, 알려진 주식에 대한 뉴스는 넘치나 잘 안알려진 주식에 대한 뉴스는 없거나 적을 것을 예상할 수 있음. \n",
    "\n",
    "아래와 같이 데이터 커버리지를 확인하여 이 사실을 확인할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 뉴스 긍/부정 레이블링 \n",
    "\n",
    "어떤 뉴스가 긍정적이냐 부정적이냐는 판단하기 어려운 문제. 한진칼(180640)의 경우 조양호 회장의 사망 이후 오히려 주가가 올랐고 (\"긍정적\" 뉴스), 엔씨소프트(036570)의 경우 TL(쓰론즈 앤 리버티) 신작을 발표한 이후 오히려 주가가 하락했음. (\"부정적\" 뉴스)\n",
    "\n",
    "따라서 본 분석에선 그 날 주식시장의 등락이 장마감 후 뉴스 기사의 sentiment를 결정한다고 \"가정\"한다. 즉, 주식이 상승마감했을 경우 긍정 / 하락마감했을 경우 부정으로 기사를 labeling한다. \n",
    "\n",
    "단, 약보합 등의 미미한 변화에 대해 sentiment가 레이블링되어 모델에 노이즈가 더해지는 것을 막기 위해 일정 강도 이상의 상승/하락만 사용한다. (threshold 적용)\n",
    "\n",
    "이 때, absolute threshold로 5%, 10% 이런 식으로 정하면 종목의 변동성 특성을 고려할 수 없기 때문에 20일 z-score을 이용하여 상승 하락을 time-series 방향에 대해 normalize한다. \n",
    "- 삼성전자(005930)와 같은 우량주는 코스닥 동전주보다 훨씬 변동성이 작을 것이므로, 5%만 움직여도 큰 뉴스일 수 있다. \n",
    "- time-series 방향으로 normalize하는 반면 cross-sectional 방향으로는 별도 normalization을 적용하지 않는다. 뉴스 기사의 긍부정을 레이블링하는데 주식의 고유 수익률이 필요하진 않기 때문. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 뉴스 sentiment 모델 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 뉴스 sentiment 모델 inference \n",
    "\n",
    "학습된 모델을 통해 뉴스데이터들의 sentiment score을 inference한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 뉴스 sentiment 데이터셋 구축\n",
    "\n",
    "앞에서 본 panel data 형식으로 news sentiment dataset을 구축한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
